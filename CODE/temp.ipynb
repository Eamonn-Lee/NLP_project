{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e180291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../DATASETS/salary_labelled_development_set.csv', encoding='utf-8')\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Inspect y_true column\n",
    "print(df['y_true'].dropna().unique()[:10])\n",
    "print(df['y_true'].describe())\n",
    "\n",
    "# Analyze salary text length\n",
    "df['salary_length'] = df['y_true'].astype(str).apply(len)\n",
    "print(df['salary_length'].describe())\n",
    "\n",
    "# Clean HTML tags from job ad text\n",
    "def clean_html_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "df['cleaned_ad_details'] = df['job_ad_details'].astype(str).apply(clean_html_tags)\n",
    "\n",
    "# Load multilingual BERT model and tokenizer\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Clean up text for rule-based extraction\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    cleaned = re.sub(r'<[^>]+>', '', text)              # Remove HTML tags\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()      # Normalize whitespace\n",
    "    return cleaned\n",
    "\n",
    "# Rule-based salary extraction\n",
    "def extract_salary_rule(text):\n",
    "    pattern_range = r'(\\d{3,6}\\s*[-~～]\\s*\\d{3,6})(元|PHP|人民币)?'\n",
    "    pattern_single = r'(\\d{3,6})(元|PHP|人民币)?'\n",
    "\n",
    "    match = re.search(pattern_range, text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    match = re.search(pattern_single, text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "# Get BERT embedding of a keyword (e.g. 'contact')\n",
    "def get_keyword_embedding(keyword):\n",
    "    inputs_kw = tokenizer(keyword, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs_kw = model(**inputs_kw)\n",
    "    return outputs_kw.last_hidden_state.mean(dim=1)  # Shape: (1, hidden_dim)\n",
    "\n",
    "# Extract potential contact info based on similarity to the keyword\n",
    "def extract_contact_candidate(last_hidden_states, tokens, keyword, sim_threshold=0.5):\n",
    "    kw_vector = get_keyword_embedding(keyword)\n",
    "    token_vectors = last_hidden_states.squeeze(0)\n",
    "    sims = cosine_similarity(token_vectors.numpy(), kw_vector.numpy()).squeeze()\n",
    "    candidate_indices = [i for i, sim in enumerate(sims) if sim > sim_threshold]\n",
    "    candidate_tokens = [tokens[i] for i in candidate_indices]\n",
    "    return \"\".join(candidate_tokens)\n",
    "\n",
    "# Combine salary and contact info extraction\n",
    "def extract_ad_info(ad_text):\n",
    "    cleaned = clean_text(ad_text)\n",
    "    salary_info = extract_salary_rule(cleaned)\n",
    "\n",
    "    inputs = tokenizer(cleaned, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "\n",
    "    contact_candidate_zh = extract_contact_candidate(last_hidden_states, tokens, \"联系方式\", sim_threshold=0.5)\n",
    "    contact_candidate_en = extract_contact_candidate(last_hidden_states, tokens, \"contact\", sim_threshold=0.5)\n",
    "    contact_candidate = contact_candidate_zh + \" / \" + contact_candidate_en if (contact_candidate_zh or contact_candidate_en) else \"\"\n",
    "\n",
    "    return {\n",
    "        \"salary_extracted\": salary_info,\n",
    "        \"contact_candidate\": contact_candidate\n",
    "    }\n",
    "\n",
    "# Apply to all job ads with progress bar\n",
    "tqdm.pandas()\n",
    "extracted_info = df['cleaned_ad_details'].progress_apply(extract_ad_info)\n",
    "\n",
    "# Merge extracted info into original dataframe\n",
    "info_df = pd.json_normalize(extracted_info)\n",
    "df = pd.concat([df, info_df], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
