{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset:\n",
      "Precision: 0.7811\n",
      "Recall: 0.9370\n",
      "F1 Score: 0.8519\n",
      "Accuracy: 0.8489\n",
      "\n",
      "Test dataset:\n",
      "Precision: 0.7412\n",
      "Recall: 0.9206\n",
      "F1 Score: 0.8212\n",
      "Accuracy: 0.8219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append(\"../CODE-Baseline\")  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from salary_baseline import extract_salary_with_inference\n",
    "\n",
    "\n",
    "file_path = '../../MISC/salary_labelled_development_set.csv'\n",
    "test_file_path = '../../MISC/salary_labelled_test_set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "country_currency_map = {\n",
    "    \"PH\": \"PHP\", \"AUS\": \"AUD\", \"NZ\": \"NZD\", \"SG\": \"SGD\",\n",
    "    \"MY\": \"MYR\", \"TH\": \"THB\", \"ID\": \"IDR\", \"HK\": \"HKD\"\n",
    "}\n",
    "salary_keywords=['ÂæÖÈÅá', 'salary', 'wage', 'compensation', 'remuneration', 'gaji', 'bermula', 'basic', 'pokok',\n",
    "                      'income']\n",
    "def convert_k_to_number(text):\n",
    "    # ÂåπÈÖçÂΩ¢Â¶Ç 20k„ÄÅ16.5k„ÄÅ30K ÁöÑÊï∞Â≠ó\n",
    "    def replace(match):\n",
    "        num = float(match.group(1))\n",
    "        return str(int(num * 1000))\n",
    "\n",
    "    return re.sub(r'(\\d+(?:\\.\\d+)?)k', replace, text, flags=re.IGNORECASE)\n",
    "# html -> text\n",
    "def clean_html_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "    # formate text\n",
    "    text = re.sub(r\"[‚Ä¢‚óè‚ñ™‚ñ∫‚óÜ‚òÖ‚ô¶‚úì‚úî‚¨§‚ùñ]\", \"\", text)\n",
    "    text = text.replace(\",\", \"\")\n",
    "    for _, value in country_currency_map.items():\n",
    "      text = text.replace(value, \"$\")\n",
    "    text = text.replace(\"RM\", \"$\")\n",
    "    text = text.replace(\"‡∏ø\", \"$\")\n",
    "    text = text.replace(\"AU\", \"$\")\n",
    "    text = text.replace(\"$$\", \"$\")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = re.sub(r'\\b[Tt][Oo]\\b', '-', text)\n",
    "    text = text.replace(\"and\", \"-\")\n",
    "    text = text.replace(\"Ëá≥\", \"-\")\n",
    "    text = text.replace(\"hingga ke\", \"-\")\n",
    "    text = text.replace(\"hingga\", \"-\")\n",
    "    text = text.replace(\"Hingga\", \"-\")\n",
    "    text = text.replace(\"HINGGA\", \"-\")\n",
    "    text = convert_k_to_number(text)\n",
    "    # ÊûÑÂª∫Ê≠£ÂàôË°®ËææÂºèÔºå\\bË°®Á§∫ÂçïËØçËæπÁïåÔºå|Ë°®Á§∫‚ÄúÊàñ‚Äù\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in salary_keywords) + r')\\b'\n",
    "\n",
    "    # ÊõøÊç¢‰∏∫ compensationÔºåflags=re.IGNORECASE Ë°®Á§∫‰∏çÂå∫ÂàÜÂ§ßÂ∞èÂÜô\n",
    "    text = re.sub(pattern, 'compensation', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "  \n",
    "\n",
    "def get_period(text):\n",
    "    unit_patterns = {\n",
    "        \"HOURLY\": r'(per\\s*hour|hourly|hr\\b|/hr\\b|/hour\\b|ÊôÇËñ™|ÊØèÂ∞èÊôÇ|ÊØèÂ∞èÊôÇËñ™Ë≥á|ÊØèÁØÄ)',\n",
    "        \"DAILY\": r'(per\\s*day|daily|/day\\b|Êó•Ëñ™|ÊØèÂ§©|ÊØèÊó•Ëñ™Ë≥á)',\n",
    "        \"WEEKLY\": r'(per\\s*week|weekly|/week\\b|ÈÄ±Ëñ™|ÊØèÈÄ±|ÊØèÂë®Ëñ™Ë≥á|Âë®Ëñ™)',\n",
    "        \"MONTHLY\": r'(per\\s*month|monthly|/month\\b|/Mth\\b|ÊúàËñ™|ÊØèÊúà|ÊØèÊúàËñ™Ë≥á|sebulan)',\n",
    "        \"ANNUAL\": r'(per\\s*year|yearly|annually|remuneration|super|annum|p\\.a\\.|p/a|/year\\b|Âπ¥Ëñ™|ÊØèÂπ¥|Âπ¥Â∫¶Ëñ™Ë≥á)'\n",
    "    }\n",
    "\n",
    "    text = text.lower()\n",
    "    for period, pattern in unit_patterns.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return period\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_question = \"what is the salary?\"\n",
    "pay_freq_question = \"Is the salary paid monthly, hourly, yearly, weekly, or daily?\"\n",
    "\n",
    "def get_salary_using_nFT_RoBerta(text,nation_code):\n",
    "  context=clean_html_tags(text)\n",
    "  salary_result = qa_pipeline({\"context\": context, \"question\": salary_question})\n",
    "  t_result=extract_salary_with_inference(salary_result[\"answer\"],nation_code)\n",
    "  # print(t_result)\n",
    "  if t_result!='0-0-None-None':\n",
    "    pay_freq_result = qa_pipeline({\"context\": context, \"question\": pay_freq_question})\n",
    "    period = get_period(pay_freq_result[\"answer\"])\n",
    "    if period is not None:\n",
    "        pattern = r\"(\\d+)-(\\d+)-([A-Z]+)-([A-Z]+)\"\n",
    "        match = re.match(pattern, t_result)\n",
    "        if not match:\n",
    "            return '0-0-None-None'\n",
    "          \n",
    "        min_salary, max_salary, currency, _ = match.groups()\n",
    "        return f\"{min_salary}-{max_salary}-{currency}-{period}\"\n",
    "    \n",
    "    \n",
    "  return t_result\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "df['predicted_salary'] = df.apply(\n",
    "    lambda row: get_salary_using_nFT_RoBerta(\n",
    "        f\"{row['job_title']} {row['job_ad_details']}\",\n",
    "        row['nation_short_desc']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset:\n",
      "Precision: 0.6990\n",
      "Recall: 0.7819\n",
      "F1 Score: 0.7382\n",
      "Accuracy: 0.7587\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDevelopment dataset:\\nPrecision: 0.7220\\nRecall: 0.7746\\nF1 Score: 0.7474\\nAccuracy: 0.7653\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP, FP, TN, FN\n",
    "TP = np.sum((df['predicted_salary'] == df['y_true']) & (df['y_true'] != \"0-0-None-None\"))\n",
    "FP = np.sum((df['predicted_salary'] != df['y_true']) & (df['predicted_salary'] != \"0-0-None-None\"))\n",
    "FN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] != \"0-0-None-None\"))\n",
    "TN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] == \"0-0-None-None\"))\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "accuracy = (TP + TN) / (FP + FN + TP + TN)\n",
    "\n",
    "# Print prediction vs ground truth\n",
    "# print(\"\\nüîç Prediction vs Ground Truth:\\n\")\n",
    "# for i, row in df.iterrows():\n",
    "#     predicted = row['predicted_salary']\n",
    "#     expected = row['y_true']\n",
    "#     if predicted != expected:\n",
    "#         print(f\"[{i}] ‚ùå Predicted: {predicted} | Expected: {expected}\")\n",
    "#         print(f\"{row['job_id']} {row['job_title']} {row['job_ad_details']}\")\n",
    "#         print()\n",
    "    # else:\n",
    "    #     print(f\"[{i}] ‚úÖ Matched:   {predicted}\")\n",
    "\n",
    "print(\"Development dataset:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "'''\n",
    "Development dataset:\n",
    "Precision: 0.7220\n",
    "Recall: 0.7746\n",
    "F1 Score: 0.7474\n",
    "Accuracy: 0.7653\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset:\n",
      "Precision: 0.6728\n",
      "Recall: 0.7625\n",
      "F1 Score: 0.7148\n",
      "Accuracy: 0.7425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTest dataset:\\nPrecision: 0.6903\\nRecall: 0.7520\\nF1 Score: 0.7198\\nAccuracy: 0.7460\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "df = pd.read_csv(test_file_path)\n",
    "df['predicted_salary'] = df.apply(\n",
    "    lambda row: get_salary_using_nFT_RoBerta(\n",
    "        f\"{row['job_title']} {row['job_ad_details']}\",\n",
    "        row['nation_short_desc']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "TP = np.sum((df['predicted_salary'] == df['y_true']) & (df['y_true'] != \"0-0-None-None\"))\n",
    "FP = np.sum((df['predicted_salary'] != df['y_true']) & (df['predicted_salary'] != \"0-0-None-None\"))\n",
    "FN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] != \"0-0-None-None\"))\n",
    "TN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] == \"0-0-None-None\"))\n",
    "\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "accuracy = (TP + TN) / (FP + FN + TP + TN)\n",
    "\n",
    "print(\"Test dataset:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "'''\n",
    "Test dataset:\n",
    "Precision: 0.6903\n",
    "Recall: 0.7520\n",
    "F1 Score: 0.7198\n",
    "Accuracy: 0.7460\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
