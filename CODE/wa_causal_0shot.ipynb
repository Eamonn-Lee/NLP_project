{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4be5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/huggingface/peft/blob/main/examples/int8_training/Finetune_opt_bnb_peft.ipynb\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0807e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\" # This line checks if a GPU is available and sets the device to GPU (e.g., cuda:0) or CPU.\n",
    "#device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Initialise the model and tokenizer to a pre-trained model. Suggestions: facebook/opt-350m, bigscience/bloom-560m\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df800049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'y_true'],\n",
      "    num_rows: 99\n",
      "})\n",
      "{'text': 'Job title: Restaurant Kitchen Hand\\nAbstract: We are seeking experienced Kitchen Hand to join our hospitality team.\\nEmployer: Catering HQ\\nLocation: pitttown\\nHighlights: opportunity for growth, Opportunity to work in an industry leading hospitality group, Positive, fun and supportive work culture\\nContents: We are currently searching for talented and polished Full Time Kitchen Hands to join our hospitality team.\\n Key duties\\n Thorough cleaning of the kitchen, including dishes and floors, Food preparation assistance, Stock rotation and stock control, Ensuring to follow all health and safety procedures when caring out all tasks, Any other adhoc duties as required by our fantastic Chefs and Management, Operating a commercial dishwasher to a high standard, Assist with general kitchen duties under the direction of the Head Chef.\\n The Person \\n Previous relevant experience in a high-volume catering/kitchen hand role is essential, Commercial kitchen experience essential, Knowledge of WH&S guidelines, Able to work a variety of shifts including morning, afternoons, evenings, Ability to take direction, Flexible availability, Youâ€™ll be a team player, fluent in English and have an eye for detail, Weâ€™d love it if you brought knife skills!.', 'y_true': 'OnSite'}\n"
     ]
    }
   ],
   "source": [
    "#get test data\n",
    "\n",
    "fp = \"/Users/eddiezhang/NLP_project-2/DATASETS/work_arrangements_test_set.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "df.drop(\"id\", axis=1, inplace=True) #get rid of id column\n",
    "df.rename(columns={\"job_ad\": \"text\"}, inplace=True)\n",
    "\n",
    "data = Dataset.from_pandas(df)\n",
    "#data = data.map(lambda samples: tokenizer(samples[\"text\"], truncation=True, padding=\"max_length\", max_length=512), batched=True)\n",
    "#data.set_format(\"torch\")    #conversion to pyTorch tensors\n",
    "\n",
    "print(data)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a723ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_format(example):\n",
    "    prompt = f\"{example['text']}\\nWhat is the work arrangement of this job ad? You must return either Onsite, Remote or Hybrid\\n Label:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23d0e9",
   "metadata": {},
   "source": [
    "GPU safety checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a615a806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memory allocated:\", torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d763b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 0 / 99 == 0.0\n",
      "correct: 0 / 99 == 0.0\n"
     ]
    }
   ],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "valid = 0\n",
    "correct = 0\n",
    "answers = [\"Onsite\", \"Remote\", \"Hybrid\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(data)):\n",
    "    #for i in range(10):\n",
    "        sample = prompt_format(data[i])\n",
    "        input = tokenizer(sample, return_tensors=\"pt\").to(device)\n",
    "        output_tokens = model.generate(**input, do_sample=False, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, max_new_tokens=10)\n",
    "\n",
    "        out_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "        out_text = out_text[len(sample):]   #raw new output\n",
    "        #print(out_text)\n",
    "\n",
    "        if out_text[0] in answers:\n",
    "            valid += 1\n",
    "            if out_text[0] == sample['y_true']:\n",
    "                correct += 1\n",
    "\n",
    "print(f\"Valid: {valid} / {len(data)} == {valid / len(data)}\")\n",
    "print(f\"correct: {correct} / {len(data)} == {correct / len(data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
