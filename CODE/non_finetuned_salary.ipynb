{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d14424",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 130\u001b[0m\n\u001b[1;32m    128\u001b[0m encoded_train_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(train_labels)\n\u001b[1;32m    129\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 130\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(train_embeddings, encoded_train_labels)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# === Testing ===\u001b[39;00m\n\u001b[1;32m    135\u001b[0m test_embeddings, test_labels \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1224\u001b[0m     X,\n\u001b[1;32m   1225\u001b[0m     y,\n\u001b[1;32m   1226\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[1;32m   1228\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1230\u001b[0m )\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[1;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m             )\n\u001b[0;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# === Device setup ===\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# === Load datasets ===\n",
    "dev_data = pd.read_csv('/Users/eddiezhang/Downloads/job_data_files/salary_labelled_development_set.csv')\n",
    "test_data = pd.read_csv('/Users/eddiezhang/Downloads/job_data_files/salary_labelled_test_set.csv')\n",
    "\n",
    "# === Map country to currency ===\n",
    "nation_currency = {\n",
    "    \"PH\": \"PHP\", \"NZ\": \"NZD\", \"AUS\": \"AUD\", \"HK\": \"HKD\",\n",
    "    \"ID\": \"IDR\", \"MY\": \"MYR\", \"SG\": \"SGD\", \"TH\": \"THB\"\n",
    "}\n",
    "dev_data['currency'] = dev_data.iloc[:, 3].map(nation_currency)\n",
    "test_data['currency'] = test_data.iloc[:, 3].map(nation_currency)\n",
    "\n",
    "# === Parse salary info ===\n",
    "def parse_actual_info(info_str):\n",
    "    try:\n",
    "        parts = info_str.split('-')\n",
    "        if len(parts) != 4 or parts == ['0', '0', 'None', 'None']:\n",
    "            return None\n",
    "        return (float(parts[0]), float(parts[1]), parts[2], parts[3].lower())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "dev_data['parsed'] = dev_data.iloc[:, 5].apply(parse_actual_info)\n",
    "test_data['parsed'] = test_data.iloc[:, 5].apply(parse_actual_info)\n",
    "dev_data = dev_data[dev_data['parsed'].notnull()]\n",
    "test_data = test_data[test_data['parsed'].notnull()]\n",
    "dev_data[['min_salary', 'max_salary', 'currency', 'unit']] = pd.DataFrame(dev_data['parsed'].tolist(), index=dev_data.index)\n",
    "test_data[['min_salary', 'max_salary', 'currency', 'unit']] = pd.DataFrame(test_data['parsed'].tolist(), index=test_data.index)\n",
    "\n",
    "# === Load BERT ===\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert.to(device)\n",
    "bert.eval()\n",
    "\n",
    "# === Helpers ===\n",
    "def label_tokens(text, salary_span):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    labels = ['O'] * len(tokens)\n",
    "    salary_tokens = tokenizer.tokenize(salary_span)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i:i+len(salary_tokens)] == salary_tokens:\n",
    "            labels[i] = 'B-SALARY'\n",
    "            for j in range(1, len(salary_tokens)):\n",
    "                labels[i + j] = 'I-SALARY'\n",
    "            break\n",
    "    return tokens, labels\n",
    "\n",
    "def get_token_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "def extract_span(tokens, labels):\n",
    "    span_tokens = []\n",
    "    inside = False\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label == \"B-SALARY\":\n",
    "            span_tokens = [token]\n",
    "            inside = True\n",
    "        elif label == \"I-SALARY\" and inside:\n",
    "            span_tokens.append(token)\n",
    "        elif inside:\n",
    "            break\n",
    "    return tokenizer.convert_tokens_to_string(span_tokens)\n",
    "\n",
    "def extract_numeric_range(span_str):\n",
    "    numbers = re.findall(r'\\d+(?:\\.\\d+)?', span_str)\n",
    "    if len(numbers) == 1:\n",
    "        val = float(numbers[0])\n",
    "        return val, val\n",
    "    elif len(numbers) >= 2:\n",
    "        return float(numbers[0]), float(numbers[1])\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def predict_currency(text):\n",
    "    for cur in [\"PHP\", \"NZD\", \"AUD\", \"HKD\", \"IDR\", \"MYR\", \"SGD\", \"THB\"]:\n",
    "        if cur.lower() in text.lower():\n",
    "            return cur\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "def predict_timeframe(text):\n",
    "    keywords = {\n",
    "        \"hourly\": [\"hour\", \"hr\", \"hourly\", \"ÊØèÂ∞èÊôÇ\", \"ÊôÇËñ™\"],\n",
    "        \"daily\": [\"day\", \"daily\", \"Êó•Ëñ™\", \"ÊØèÊó•\"],\n",
    "        \"weekly\": [\"week\", \"weekly\", \"Âë®Ëñ™\", \"ÊØèÈÄ±\"],\n",
    "        \"monthly\": [\"month\", \"monthly\", \"ÊúàËñ™\", \"ÊØèÊúà\"],\n",
    "        \"annual\": [\"year\", \"annual\", \"yearly\", \"annually\", \"Âπ¥Ëñ™\", \"ÊØèÂπ¥\"]\n",
    "    }\n",
    "    for unit, terms in keywords.items():\n",
    "        for t in terms:\n",
    "            if t in text.lower():\n",
    "                return unit\n",
    "    return \"unknown\"\n",
    "\n",
    "# === Training ===\n",
    "train_embeddings, train_labels = [], []\n",
    "\n",
    "for idx, row in dev_data.iterrows():\n",
    "    job_text = row.iloc[2]\n",
    "    salary_span = f\"{int(row['min_salary'])} to {int(row['max_salary'])}\"\n",
    "    tokens, labels = label_tokens(job_text, salary_span)\n",
    "    embeddings = get_token_embeddings(job_text)\n",
    "\n",
    "    if embeddings.shape[0] != len(tokens) or \"B-SALARY\" not in labels:\n",
    "        continue\n",
    "\n",
    "    train_embeddings.extend(embeddings.numpy())\n",
    "    train_labels.extend(labels)\n",
    "\n",
    "\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_train_labels = label_encoder.fit_transform(train_labels)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_embeddings, encoded_train_labels)\n",
    "\n",
    "\n",
    "# === Testing ===\n",
    "test_embeddings, test_labels = [], []\n",
    "test_tokens_list, test_true_labels_list = [], []\n",
    "skipped_test = 0\n",
    "\n",
    "for idx, row in dev_data.iterrows():\n",
    "    job_text = row.iloc[2]\n",
    "    salary_span = f\"{int(row['min_salary'])} to {int(row['max_salary'])}\"\n",
    "\n",
    "    if salary_span not in job_text:\n",
    "        continue\n",
    "\n",
    "    tokens, labels = label_tokens(job_text, salary_span)\n",
    "    embeddings = get_token_embeddings(job_text)\n",
    "\n",
    "    if embeddings.shape[0] != len(tokens):\n",
    "        continue\n",
    "\n",
    "    train_embeddings.extend(embeddings.numpy())\n",
    "    train_labels.extend(labels)\n",
    "\n",
    "test_preds = clf.predict(test_embeddings)\n",
    "id2label = {i: label for i, label in enumerate(label_encoder.classes_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a5136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Final Structured Predictions by Test Row\n",
      "----------------------------------------------------------------------\n",
      "[Row 0]\n",
      "Prediction: 0-0-NONE-NONE\n",
      "Actual:     1500-1800-MYR-monthly\n",
      "‚ùå INCORRECT\n",
      "\n",
      "[Row 1]\n",
      "Prediction: 0-0-NONE-NONE\n",
      "Actual:     60-60-HKD-hourly\n",
      "‚ùå INCORRECT\n",
      "\n",
      "üîö Structured Prediction Summary\n",
      "----------------------------------------------------------------------\n",
      "‚úîÔ∏è Total Test Rows Evaluated:   2\n",
      "üéØ Fully Correct Predictions:   0\n",
      "üéØ Final Match Accuracy:        0.00%\n"
     ]
    }
   ],
   "source": [
    "# === Evaluation: Full prediction vs actual ===\n",
    "print(\"\\nüßæ Final Structured Predictions by Test Row\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "correct_full_match = 0\n",
    "total_rows = 0\n",
    "start_idx = 0\n",
    "\n",
    "for i, row in enumerate(test_data.itertuples()):\n",
    "    if i >= len(test_tokens_list):\n",
    "        break\n",
    "\n",
    "    job_text = row.job_ad_details\n",
    "    true_currency = getattr(row, \"currency\")\n",
    "    true_unit = getattr(row, \"unit\").lower()\n",
    "    true_min = int(getattr(row, \"min_salary\"))\n",
    "    true_max = int(getattr(row, \"max_salary\"))\n",
    "\n",
    "    tokens = test_tokens_list[i]\n",
    "    true_labels = test_true_labels_list[i]\n",
    "\n",
    "    \n",
    "    end_idx = start_idx + len(tokens)\n",
    "    pred_labels = [id2label[idx] for idx in test_preds[start_idx:end_idx]]\n",
    "    start_idx = end_idx\n",
    "\n",
    "    pred_span = extract_span(tokens, pred_labels)\n",
    "    pred_min, pred_max = extract_numeric_range(pred_span)\n",
    "    pred_currency = predict_currency(job_text)\n",
    "    pred_unit = predict_timeframe(job_text)\n",
    "\n",
    "    if pred_min is not None and pred_max is not None:\n",
    "        pred_string = f\"{int(pred_min)}-{int(pred_max)}-{pred_currency}-{pred_unit}\"\n",
    "    else:\n",
    "        pred_string = f\"0-0-NONE-NONE\"\n",
    "\n",
    "    true_string = f\"{true_min}-{true_max}-{true_currency}-{true_unit}\"\n",
    "    is_correct = pred_string.lower() == true_string.lower()\n",
    "\n",
    "    correct_full_match += int(is_correct)\n",
    "    total_rows += 1\n",
    "\n",
    "    print(f\"[Row {i}]\")\n",
    "    print(f\"Prediction: {pred_string}\")\n",
    "    print(f\"Actual:     {true_string}\")\n",
    "    print(\"‚úÖ CORRECT\" if is_correct else \"‚ùå INCORRECT\")\n",
    "    print()\n",
    "\n",
    "print(\"üîö Structured Prediction Summary\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"‚úîÔ∏è Total Test Rows Evaluated:   {total_rows}\")\n",
    "print(f\"üéØ Fully Correct Predictions:   {correct_full_match}\")\n",
    "print(f\"üéØ Final Match Accuracy:        {correct_full_match / total_rows * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
