{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/eddiezhang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/eddiezhang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# === Constants ===\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<END>\"\n",
    "LABELS = [\"B-SALARY\", \"I-SALARY\", \"O\"]\n",
    "NUMBER_RE = re.compile(r\"\\d+(?:\\.\\d+)?\")\n",
    "CLEAN_HTML_RE = re.compile(r\"<[^>]+>\")\n",
    "MULTI_SPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "# === Salary Lexicon from WordNet ===\n",
    "# Download WordNet + Open Multilingual WordNet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def get_au_multilingual_salary_terms():\n",
    "    # Seed English terms related to salary\n",
    "    seed_words = [\n",
    "        \"salary\", \"wage\", \"pay\", \"income\", \"compensation\", \n",
    "        \"remuneration\", \"bonus\", \"allowance\", \"earnings\", \"reimbursement\",\n",
    "        \"payment\", \"benefit\", \"commission\", \"gratuity\"\n",
    "    ]\n",
    "\n",
    "    # Prominent languages in Australia\n",
    "    au_languages = [\n",
    "        \"eng\",  # English\n",
    "        \"cmn\",  # Mandarin\n",
    "        \"arb\",  # Arabic\n",
    "        \"vie\",  # Vietnamese\n",
    "        \"ita\",  # Italian\n",
    "        \"ell\",  # Greek\n",
    "        \"hin\",  # Hindi\n",
    "        \"spa\",  # Spanish\n",
    "        \"tgl\",  # Tagalog/Filipino\n",
    "        \"kor\",  # Korean\n",
    "        \"tha\",  # Thai\n",
    "        \"urd\"   # Urdu\n",
    "    ]\n",
    "\n",
    "    lexicon = set()\n",
    "\n",
    "    for word in seed_words:\n",
    "        eng_synsets = wn.synsets(word, lang=\"eng\")\n",
    "        for synset in eng_synsets:\n",
    "            for lang in au_languages:\n",
    "                if lang in synset._lemma_names:\n",
    "                    translated = synset.lemma_names(lang)\n",
    "                    lexicon.update(lemma.lower().replace(\"_\", \" \") for lemma in translated)\n",
    "\n",
    "\n",
    "    return lexicon\n",
    "\n",
    "SALARY_LEX = get_au_multilingual_salary_terms()\n",
    "# === Helper Functions ===\n",
    "def parse_actual_info(info_str):\n",
    "    parts = info_str.split(\"-\")\n",
    "    if len(parts) != 4 or parts == ['0', '0', 'None', 'None']:\n",
    "        return None\n",
    "    return float(parts[0]), float(parts[1]), parts[2], parts[3].lower()\n",
    "\n",
    "def round_numbers(text):\n",
    "    # round any x.y to integer\n",
    "    def _repl(m):\n",
    "        return str(int(round(float(m.group()), 0)))\n",
    "    return re.sub(r\"\\d+\\.\\d+\", _repl, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # 1) normalize weird splits: \"1500. 0\" or \"21. 20\" → \"1500.0\", \"21.20\"\n",
    "    text = re.sub(r\"(\\d+)\\.\\s+(\\d+)\", r\"\\1.\\2\", text)\n",
    "    # 2) round any remaining decimals to ints: \"1500.0\" → \"1500\"\n",
    "    text = round_numbers(text)\n",
    "    # 3) strip HTML tags & collapse whitespace\n",
    "    text = CLEAN_HTML_RE.sub(\"\", text)\n",
    "    text = MULTI_SPACE_RE.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_html_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def chunk_and_align(text, min_salary, max_salary, tokenizer,\n",
    "                    max_length=512, context=128):\n",
    "    # 1) find all number matches for min and max\n",
    "    occurrences = [(m.start(), m.end(), float(m.group()))\n",
    "                   for m in NUMBER_RE.finditer(text)]\n",
    "    if not occurrences:\n",
    "        return [], [], []\n",
    "\n",
    "    # 2) filter to only exact min/max\n",
    "    min_pos = [(s, e) for (s, e, v) in occurrences\n",
    "               if abs(v - min_salary) < 1e-3]\n",
    "    max_pos = [(s, e) for (s, e, v) in occurrences\n",
    "               if abs(v - max_salary) < 1e-3]\n",
    "\n",
    "    # 2b) if no exact match, pick the occurrence _closest_ to the target\n",
    "    if not min_pos:\n",
    "        s, e, v = min(occurrences, key=lambda x: abs(x[2] - min_salary))\n",
    "        min_pos = [(s, e)]\n",
    "    if not max_pos:\n",
    "        s, e, v = min(occurrences, key=lambda x: abs(x[2] - max_salary))\n",
    "        max_pos = [(s, e)]\n",
    "\n",
    "    # 3) pick char-span strictly between closest min & max\n",
    "    start_char = min(p[0] for p in min_pos)\n",
    "    end_char   = max(p[1] for p in max_pos)\n",
    "\n",
    "    # 4) expand by a bit of context\n",
    "    start_char = max(0, start_char - context)\n",
    "    end_char   = min(len(text), end_char + context)\n",
    "    window_text = text[start_char:end_char]\n",
    "\n",
    "    # 5) tokenize just that slice\n",
    "    inputs = tokenizer(\n",
    "        window_text,\n",
    "        return_offsets_mapping = True,\n",
    "        truncation = True,\n",
    "        max_length = max_length,\n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "    offsets = inputs.pop(\"offset_mapping\")[0].tolist()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "    # 6) compute lexicon feature per token\n",
    "    lex_feats = [1 if tok.lower() in SALARY_LEX else 0 for tok in tokens]\n",
    "    lex_tensor = torch.tensor(lex_feats, dtype = torch.float, device = device).unsqueeze(1)\n",
    "\n",
    "    # 7) label tokens by overlap with original numeric span\n",
    "    labels = []\n",
    "    saw_B = False\n",
    "    for (s, e), tok in zip(offsets, tokens):\n",
    "        s_orig = s + start_char\n",
    "        e_orig = e + start_char\n",
    "        if e_orig > start_char + context and s_orig < end_char - context:\n",
    "            labels.append(\"B-SALARY\" if not saw_B else \"I-SALARY\")\n",
    "            saw_B = True\n",
    "        else:\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    # 8) BERT pass + concat lex feature\n",
    "    with torch.no_grad():\n",
    "        out = bert_model(\n",
    "            input_ids = inputs[\"input_ids\"].to(device),\n",
    "            attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        )\n",
    "    embeddings = out.last_hidden_state.squeeze(0)\n",
    "    embeddings = torch.cat([embeddings, lex_tensor], dim = 1)\n",
    "\n",
    "    return [tokens], [labels], [embeddings]\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, torch.argmax(vec, dim = 1)]\n",
    "    max_score_b = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_b)))\n",
    "\n",
    "def prepare_sequence(embeds):\n",
    "    return embeds.view(len(embeds), 1, -1)\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tag_to_ix):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers = 1, bidirectional = True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (\n",
    "            torch.randn(2, 1, self.hidden_dim // 2, device = device),\n",
    "            torch.randn(2, 1, self.hidden_dim // 2, device = device)\n",
    "        )\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000., device = device)\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0\n",
    "        forward_var = init_alphas\n",
    "        for feat in feats:\n",
    "            alphas_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        return log_sum_exp(terminal_var)\n",
    "\n",
    "    def _get_lstm_features(self, embeds):\n",
    "        self.hidden = self.init_hidden()\n",
    "        lstm_out, _ = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(embeds), self.hidden_dim)\n",
    "        return self.hidden2tag(lstm_out)\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        score = torch.zeros(1, device = device)\n",
    "        tags = torch.cat([\n",
    "            torch.tensor([self.tag_to_ix[START_TAG]], dtype = torch.long, device = device),\n",
    "            tags\n",
    "        ])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score += self.transitions[tags[i+1], tags[i]] + feat[tags[i+1]]\n",
    "        score += self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000., device = device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []\n",
    "            vvars_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = torch.argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                vvars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            forward_var = torch.cat(vvars_t).view(1, -1) + feat\n",
    "            backpointers.append(bptrs_t)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = torch.argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs in reversed(backpointers):\n",
    "            best_tag_id = bptrs[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        assert best_path.pop() == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, embeds, tags):\n",
    "        feats = self._get_lstm_features(embeds)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, embeds):\n",
    "        lstm_feats = self._get_lstm_features(embeds)\n",
    "        return self._viterbi_decode(lstm_feats)\n",
    "\n",
    "# === Setup ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\").to(device).eval()\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# === Data Preprocessing ===\n",
    "dev_data = pd.read_csv(\"/Users/eddiezhang/Downloads/job_data_files/salary_labelled_development_set.csv\")\n",
    "nation_currency = {\n",
    "    \"PH\": \"PHP\", \"NZ\": \"NZD\", \"AUS\": \"AUD\", \"HK\": \"HKD\",\n",
    "    \"ID\": \"IDR\", \"MY\": \"MYR\", \"SG\": \"SGD\", \"TH\": \"THB\"\n",
    "}\n",
    "dev_data['currency'] = dev_data.iloc[:, 3].map(nation_currency)\n",
    "dev_data['parsed'] = dev_data.iloc[:, 5].apply(parse_actual_info)\n",
    "dev_data[['min_salary', 'max_salary', 'currency', 'unit']] = pd.DataFrame(\n",
    "    dev_data['parsed'].tolist(), index = dev_data.index\n",
    ")\n",
    "dev_data['cleaned_ad_details'] = dev_data['job_ad_details'].astype(str).apply(clean_html_tags).apply(clean_text)\n",
    "\n",
    "# === Build Training Set ===\n",
    "tag_to_ix = {label: i for i, label in enumerate(LABELS)}\n",
    "tag_to_ix[START_TAG] = len(tag_to_ix)\n",
    "tag_to_ix[STOP_TAG] = len(tag_to_ix)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for _, row in dev_data.iterrows():\n",
    "    parsed = row['parsed']\n",
    "    if not parsed:\n",
    "        continue\n",
    "    token_chunks, label_chunks, embed_chunks = chunk_and_align(\n",
    "        row['cleaned_ad_details'], parsed[0], parsed[1], tokenizer\n",
    "    )\n",
    "    for labels, embeddings in zip(label_chunks, embed_chunks):\n",
    "        if len(labels) != embeddings.shape[0]:\n",
    "            continue\n",
    "        X_train.append(embeddings)\n",
    "        Y_train.append(torch.tensor(\n",
    "            [tag_to_ix[l] for l in labels],\n",
    "            dtype = torch.long,\n",
    "            device = device\n",
    "        ))\n",
    "\n",
    "# === Train Model ===\n",
    "model = BiLSTM_CRF(\n",
    "    embedding_dim = bert_model.config.hidden_size + 1,\n",
    "    hidden_dim = 128,\n",
    "    tag_to_ix = tag_to_ix\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0.0\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        model.zero_grad()\n",
    "        feats = prepare_sequence(x)\n",
    "        loss = model.neg_log_likelihood(feats, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "459eaf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Evaluation ===\n",
      "\n",
      "[❌] Job ID 72527377\n",
      "    Raw span:    '1500'\n",
      "    Formatted:   '1500-1500-MYR-MONTHLY'\n",
      "    Expected:    '1500-1800-MYR-MONTHLY'\n",
      "\n",
      "[✅] Job ID 73593343\n",
      "    Raw span:    '60'\n",
      "    Formatted:   '60-60-HKD-HOURLY'\n",
      "    Expected:    '60-60-HKD-HOURLY'\n",
      "\n",
      "[✅] Job ID 60150523\n",
      "    Raw span:    '21'\n",
      "    Formatted:   '21-21-NZD-HOURLY'\n",
      "    Expected:    '21-21-NZD-HOURLY'\n",
      "\n",
      "[✅] Job ID 79030770\n",
      "    Raw span:    '32'\n",
      "    Formatted:   '32-32-AUD-HOURLY'\n",
      "    Expected:    '32-32-AUD-HOURLY'\n",
      "\n",
      "[❌] Job ID 68264916\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '2000-3000-MYR-MONTHLY'\n",
      "\n",
      "[✅] Job ID 70451682\n",
      "    Raw span:    '3000Incentives : RM500 - 1000Total Package : MYR 3000 [UNK] MYR 4000 / MonthOther'\n",
      "    Formatted:   '3000-4000-MYR-MONTHLY'\n",
      "    Expected:    '3000-4000-MYR-MONTHLY'\n",
      "\n",
      "[❌] Job ID 72593577\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '80-90-HKD-HOURLY'\n",
      "\n",
      "[❌] Job ID 60040933\n",
      "    Raw span:    '142642 - $ 156491 Fortnightly salary $ 5468 - $ 5998'\n",
      "    Formatted:   '142642-5998-AUD-ANNUAL'\n",
      "    Expected:    '142642-156491-AUD-ANNUAL'\n",
      "\n",
      "[✅] Job ID 75689864\n",
      "    Raw span:    '29'\n",
      "    Formatted:   '29-29-AUD-HOURLY'\n",
      "    Expected:    '29-29-AUD-HOURLY'\n",
      "\n",
      "[❌] Job ID 71709020\n",
      "    Raw span:    '1500'\n",
      "    Formatted:   '1500-1500-MYR-MONTHLY'\n",
      "    Expected:    '1500-2500-MYR-MONTHLY'\n",
      "\n",
      "[✅] Job ID 77127266\n",
      "    Raw span:    '66028 - $ 68086'\n",
      "    Formatted:   '66028-68086-AUD-ANNUAL'\n",
      "    Expected:    '66028-68086-AUD-ANNUAL'\n",
      "\n",
      "[❌] Job ID 72197888\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '3000-4000-SGD-MONTHLY'\n",
      "\n",
      "[❌] Job ID 78996497\n",
      "    Raw span:    '00 - 12 : 30 或 13 : 30 - 17 : 00'\n",
      "    Formatted:   '0-0-HKD-HOURLY'\n",
      "    Expected:    '73-85-HKD-HOURLY'\n",
      "\n",
      "[❌] Job ID 71491873\n",
      "    Raw span:    'Certification in : AS 9120, IATF 16949, ISO 9001, ISO 13485, ISO 14001, ISO 22301, ISO 26000, ISO 27001, ISO 28000, ISO 29001, ISO 45001, ISO 50001, and ISO 37000'\n",
      "    Formatted:   '9120-37000-MYR-MONTHLY'\n",
      "    Expected:    '5000-8000-MYR-MONTHLY'\n",
      "\n",
      "[❌] Job ID 73201781\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '30-30-NZD-HOURLY'\n",
      "\n",
      "[❌] Job ID 72348327\n",
      "    Raw span:    '500 to $ 1, 250Summary of role requirements : Looking for candidates available to work : Monday : Morning, AfternoonTuesday : Morning, AfternoonWednesday : Morning, AfternoonThursday : Afternoon, MorningFriday : Morning, AfternoonSaturday : Morning, Afternoon'\n",
      "    Formatted:   '500-250-SGD-WEEKLY'\n",
      "    Expected:    '500-1250-SGD-WEEKLY'\n",
      "\n",
      "[✅] Job ID 77460478\n",
      "    Raw span:    '1500'\n",
      "    Formatted:   '1500-1500-MYR-MONTHLY'\n",
      "    Expected:    '1500-1500-MYR-MONTHLY'\n",
      "\n",
      "[❌] Job ID 69807967\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '750-1125-SGD-WEEKLY'\n",
      "\n",
      "[❌] Job ID 73412847\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '1500-1500-MYR-MONTHLY'\n",
      "\n",
      "[❌] Job ID 69884532\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '2000-2500-SGD-MONTHLY'\n",
      "\n",
      "[✅] Job ID 69096815\n",
      "    Raw span:    '58008'\n",
      "    Formatted:   '58008-58008-AUD-ANNUAL'\n",
      "    Expected:    '58008-58008-AUD-ANNUAL'\n",
      "\n",
      "[✅] Job ID 75679535\n",
      "    Raw span:    '23 per hour to $ 29'\n",
      "    Formatted:   '23-29-NZD-HOURLY'\n",
      "    Expected:    '23-29-NZD-HOURLY'\n",
      "\n",
      "[✅] Job ID 65820039\n",
      "    Raw span:    '##3000 - RM6000'\n",
      "    Formatted:   '3000-6000-MYR-MONTHLY'\n",
      "    Expected:    '3000-6000-MYR-MONTHLY'\n",
      "\n",
      "[✅] Job ID 77300030\n",
      "    Raw span:    '31'\n",
      "    Formatted:   '31-31-NZD-HOURLY'\n",
      "    Expected:    '31-31-NZD-HOURLY'\n",
      "\n",
      "[❌] Job ID 74881613\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '100-100-HKD-HOURLY'\n",
      "\n",
      "[❌] Job ID 69347431\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '500-667-PHP-DAILY'\n",
      "\n",
      "[❌] Job ID 67924197\n",
      "    Raw span:    'spectrum of recruitment cycle including preparing and posting of job descriptions, interviewing, and handling on / off - boarding. Process employee data in the HRIS system and monthly payroll to ensure its accuracy. Coordinate the day - to - day workflow of subordinates in the HR department. Provide advisories to the management with regard to employment issues which includes labour legislations, best local labour practices, company manpower practices and ensure legal compliances with all statutory requirements. Review human resources policies and procedures. Hands on with HR issues such as employee relations, grievances, complaints and provide counselling / guidance. Prepare and discuss on regular HR reports. Monitor performance, identify and facilitate opportunities to increase productivity and efficiency. Maintain employee morale by fostering a positive working environment through effective leadership and teamwork. Main point of contact for all employee relations matters. Perform any other related duties as and when assigned by the management. Timely submission of claims and training grants to various government agencies / statutory bodies. Submission of various statutory surveys. Requirements : Bachelor ' s degree in Human Resources or related disciplines. Minimum 5 years of HR experience. Excellent verbal and written communication skills. High degree of integrity and discipline. Ability to create, present and execute ideas, reports, and budgets. Ability to work both independently and collaboratively in a fast - paced environment. Proficient with Microsoft Office Suite especially Word and Excel. Strong knowledge in local employment laws and best practice. Summary of Role Requirements : Looking for candidates available to work : Monday : Morning, Afternoon Tuesday : Morning, Afternoon Wednesday : Morning, Afternoon Thursday : Morning, Afternoon Friday : Morning, Afternoon 2 - 3 years of relevant work experience required for this role. Working rights required for this role. Expected salary : $ 107 - $ 150 per day. # J - 18808'\n",
      "    Formatted:   '5-18808-SGD-DAILY'\n",
      "    Expected:    '107-150-SGD-DAILY'\n",
      "\n",
      "[❌] Job ID 78720309\n",
      "    Raw span:    '1500 + OT ( RM10'\n",
      "    Formatted:   '1500-10-MYR-MONTHLY'\n",
      "    Expected:    '1500-1500-MYR-MONTHLY'\n",
      "\n",
      "[❌] Job ID 72808306\n",
      "    Raw span:    'cattle producing regions to produce a diverse range of pasture fed and grain beef products, from commodity to premium. The renowned AMH brand, the award - winning Yardstick, the highly marbled grain fed Pure Prime and our state [UNK] s brand, Queenslander Beef and more are all produced at Dinmore. With the expansion of JBS Dinmore ' s afternoon shift opening in January 2024, this is a great opportunity to enter into a career at an entry level with no experience necessary. With endless opportunities within the company it [UNK] s up to you how far you go!! # ItallstartshereAs a Process worker you will have experience in or be eager to train and work in various areas of our meat processing plant. This is a fast - paced physical role with a focus on safety and quality. Work schedule for 2024 : Afternoon shift | Monday to Thursday - 3pm to 1am dailyReumeration : Entry level | $ 25'\n",
      "    Formatted:   '2024-25-AUD-HOURLY'\n",
      "    Expected:    '20-25-AUD-HOURLY'\n",
      "\n",
      "[❌] Job ID 68457494\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '2700-3000-SGD-MONTHLY'\n",
      "\n",
      "[❌] Job ID 79005714\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '2300-2700-SGD-MONTHLY'\n",
      "\n",
      "[✅] Job ID 76979175\n",
      "    Raw span:    '61868'\n",
      "    Formatted:   '61868-61868-AUD-ANNUAL'\n",
      "    Expected:    '61868-61868-AUD-ANNUAL'\n",
      "\n",
      "[❌] Job ID 71104935\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '16000-16000-PHP-MONTHLY'\n",
      "\n",
      "[❌] Job ID 68453575\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '25-30-NZD-HOURLY'\n",
      "\n",
      "[❌] Job ID 78132617\n",
      "    Raw span:    '54Baguio2600CARPhilippines Company Information Foundever Job Description Manage large amounts of incoming phone calls Generate sales leads Identify and assess customers ' needs to achieve satisfaction Build sustainable relationships and trust with customer accounts through open and interactive communication Provide accurate, valid and complete information by using the right methods / tools Meet personal / customer service team sales targets and call handling quotas Handle customer complaints, provide appropriate solutions and alternatives within the time limits ; follow up to ensure resolution Keep records of customer interactions, process customer accounts and file documents Job Qualifications Proven customer support experience or experience as a Client Service Representative Track record of over - achieving quota Strong phone contact handling skills and active listening Familiarity with CRM systems and practices Customer orientation and ability to adapt / respond to different types of characters Excel'\n",
      "    Formatted:   '54-2600-HKD-WEEKLY'\n",
      "    Expected:    '3750-5000-HKD-WEEKLY'\n",
      "\n",
      "[✅] Job ID 78970505\n",
      "    Raw span:    '##1500 • Unlimited commission • Monthly performance incentive • Higher Education Allowance • Internal Promotion • Staff Voucher • Group Insurance Coverage • Medical and Dental Claim • SOCSO and KWSP • Annual Dinner Requirements : • Minimum SPM / SKM CERTIFICATE qualification and above. • Experience in social media livestreaming, and able to produce short video. • Self - motivated, target driven and passionate in the sales & services industry. • The right attitude and interest to learn & grow in the retail industry. • Humble and willing to learn. • Working experience will be an added advantage. PLEASE CONTACT ME AT THIS NUMBER : MR. NAZMI 013 - 5911800 Tanggungjawab : • Melayan pelanggan yang datang ke cawangan dan mengambil tahu apa yang setiap pelanggan mahu atau perlukan. • Beri pandangan, pilih dan bantu mencari atau mendapatkan produk berdasarkan keperluan dan keinginan pelanggan. • Terangkan barangan dan terangkan operasi penggunaan, dan penjagaan produk kepada pelanggan. • Sediakan salinan invois jualan atau resit jualan untuk rujukan pelanggan. • Tunjukkan penggunaan atau pengendalian produk. • Bantu pelanggan mencuba produk untuk memastikan produk berada dalam keadaan baik dan berfungsi sebelum membeli. • Menyediakan maklumat tentang jaminan, spesifikasi pembuatan, penjagaan dan penyelenggaraan produk dan pilihan penghantaran. • Mendidik dan memaklumkan pelanggan tentang faedah dan ciri produk syarikat. Faedah : • Gaji pokok sebulan RM1500 • Komisen tanpa had • Insentif prestasi bulanan • Elaun Pendidikan Tinggi • Promosi Dalaman • Baucar Kakitangan • Perlindungan Insura'\n",
      "    Formatted:   '1500-1500-MYR-MONTHLY'\n",
      "    Expected:    '1500-1500-MYR-MONTHLY'\n",
      "\n",
      "[❌] Job ID 78411238\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '500-800-SGD-MONTHLY'\n",
      "\n",
      "[❌] Job ID 78987295\n",
      "    Raw span:    '##Prepares, posts, verifies, and records customer payments and transactions related to accounts receivableCreates Debit Notes according to company practicesMaintains and updates customer files, including terms, limits, name or address changes, mergers, or mailing attentionsPrepare Customer Statement of AccountsApplicants who possess relevant experience for the above responsibilities are most welcome to apply. If you do not possess the above experience, your application will still be considered on individual merits and you may be contacted for other opportunities. Please submit your updated resume in MS Words format by using the APPLY NOW BUTTON or 69028743. By submitting your personal data and / or resume, you give consent to collection, use and disclosure of your personal data and / or resume by the company ( or its agent ) for the purpose of the processing and administration by the company relating to this'\n",
      "    Formatted:   '69028743-69028743-HKD-WEEKLY'\n",
      "    Expected:    '625-800-HKD-WEEKLY'\n",
      "\n",
      "[❌] Job ID 71941542\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '60-60-SGD-DAILY'\n",
      "\n",
      "[❌] Job ID 72223378\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '30-30-AUD-HOURLY'\n",
      "\n",
      "[❌] Job ID 78457362\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '1800-2000-MYR-MONTHLY'\n",
      "\n",
      "[✅] Job ID 77120488\n",
      "    Raw span:    '27'\n",
      "    Formatted:   '27-27-NZD-HOURLY'\n",
      "    Expected:    '27-27-NZD-HOURLY'\n",
      "\n",
      "[❌] Job ID 67248035\n",
      "    Raw span:    '130379 - 132800 Hours Per Week : 38 Requisition ID : REQ398098 Advertising Closes : 18th May 2023 What you ' ll be doing To provide expert clinical consultancy and services within the Alcohol and other Drugs ( AOD ) Service, practicing within the CNC Domains, up to and including the functions of the CNC 3 role, and to demonstrate leadership in promoting contemporary nursing / midwifery practice within the Mid North Coast Local Health District. This position will work closely with the AOD stream managers and provide timely and expert advice to the AOD District Manager and Clinical Director on all matters related to nursing. All NSW Health workers are required to have completed a primary course of a COVID - 19 vaccine which has been approved or recognised by the Therapeutics Goods Administration ( TGA ). Additionally, Category A workers are required to receive a booster dose three months after completing the primary course of COVID - 19 vaccinations. New applicants must have completed the vaccination course prior to commencement with NSW Health, or provide an approved medical contraindication certificate ( IM011 immunisation medical exemption form ) certifying the worker cannot have any approved COVID - 19 vaccines available in NSW. Acceptable proof of vaccination is the Australian Immunisation Register ( AIR ) Immunisation History Statement or AIR COVID - 19 Digital Certificate. Booster doses are highly recommended for all health care workers who have completed the primary course of COVID - 19 vaccinations. Salary will be accordance with NSW Health State Awards for the advertised classification / s. These awards are available at http : / / www. health. nsw. gov. au / careers / conditions / pages / default. aspx. AN ELIGIBILITY LIST FROM THIS RECRUITMENT ACTIVITY MAY BE CREATED FOR FUTURE VACANCIES Current registration with the Nursing and Midwifery Board of Australia with at least 7 years full time equivalent post registration experience and post graduate qualifications with at least 5 years full time experience in the Alcohol and Other Drugs field'\n",
      "    Formatted:   '130379-5-AUD-ANNUAL'\n",
      "    Expected:    '130378-132799-AUD-ANNUAL'\n",
      "\n",
      "[❌] Job ID 74289362\n",
      "    Raw span:    ''\n",
      "    Formatted:   'NONE'\n",
      "    Expected:    '21000-21000-PHP-MONTHLY'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOverall Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Run Evaluation\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m evaluate_on_test_set(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/eddiezhang/Downloads/job_data_files/salary_labelled_test_set.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 33\u001b[0m, in \u001b[0;36mevaluate_on_test_set\u001b[0;34m(test_csv_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m min_salary, max_salary, currency, unit \u001b[38;5;241m=\u001b[39m parsed\n\u001b[1;32m     31\u001b[0m job_text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_ad_details\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m token_chunks, _, embed_chunks \u001b[38;5;241m=\u001b[39m chunk_and_align(\n\u001b[1;32m     34\u001b[0m     job_text, min_salary, max_salary, tokenizer\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m best_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNONE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m best_raw_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[20], line 142\u001b[0m, in \u001b[0;36mchunk_and_align\u001b[0;34m(text, min_salary, max_salary, tokenizer, max_length, context)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# 8) BERT pass + concat lex feature\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m bert_model(\n\u001b[1;32m    143\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m    144\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    147\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([embeddings, lex_tensor], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1143\u001b[0m     embedding_output,\n\u001b[1;32m   1144\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   1145\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1146\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1147\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m   1148\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1149\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1150\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1151\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1152\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1153\u001b[0m )\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    696\u001b[0m         hidden_states,\n\u001b[1;32m    697\u001b[0m         attention_mask,\n\u001b[1;32m    698\u001b[0m         layer_head_mask,\n\u001b[1;32m    699\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    700\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    701\u001b[0m         past_key_value,\n\u001b[1;32m    702\u001b[0m         output_attentions,\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    586\u001b[0m         hidden_states,\n\u001b[1;32m    587\u001b[0m         attention_mask,\n\u001b[1;32m    588\u001b[0m         head_mask,\n\u001b[1;32m    589\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    590\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    591\u001b[0m     )\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m    517\u001b[0m         attention_mask,\n\u001b[1;32m    518\u001b[0m         head_mask,\n\u001b[1;32m    519\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    520\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    521\u001b[0m         past_key_value,\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    438\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mscaled_dot_product_attention(\n\u001b[1;32m    441\u001b[0m     query_layer,\n\u001b[1;32m    442\u001b[0m     key_layer,\n\u001b[1;32m    443\u001b[0m     value_layer,\n\u001b[1;32m    444\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    445\u001b[0m     dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_prob \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    446\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    447\u001b[0m )\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    450\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def extract_span_from_tags(tokens, tags):\n",
    "    # find all positions where the model predicted B- or I-SALARY\n",
    "    idxs = [i for i, tag in enumerate(tags) if tag in (\"B-SALARY\", \"I-SALARY\")]\n",
    "    if not idxs:\n",
    "        return \"\"\n",
    "    start, end = min(idxs), max(idxs)\n",
    "    span_tokens = tokens[start : end + 1]\n",
    "    return tokenizer.convert_tokens_to_string(span_tokens).strip()\n",
    "\n",
    "def evaluate_on_test_set(test_csv_path):\n",
    "    test_data = pd.read_csv(test_csv_path)\n",
    "    test_data['parsed'] = test_data.iloc[:, 5].apply(parse_actual_info)\n",
    "    test_data['cleaned_ad_details'] = (\n",
    "        test_data['job_ad_details']\n",
    "        .astype(str)\n",
    "        .apply(clean_html_tags)\n",
    "        .apply(clean_text)\n",
    "    )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(\"\\n=== Test Set Evaluation ===\\n\")\n",
    "    for _, row in test_data.iterrows():\n",
    "        job_id = row['job_id']\n",
    "        y_true = row['y_true']\n",
    "        parsed = row['parsed']\n",
    "        if not parsed:\n",
    "            continue\n",
    "        min_salary, max_salary, currency, unit = parsed\n",
    "        job_text = row['cleaned_ad_details']\n",
    "\n",
    "        token_chunks, _, embed_chunks = chunk_and_align(\n",
    "            job_text, min_salary, max_salary, tokenizer\n",
    "        )\n",
    "\n",
    "        best_prediction = \"NONE\"\n",
    "        best_raw_span = \"\"\n",
    "        for tokens, embeddings in zip(token_chunks, embed_chunks):\n",
    "            with torch.no_grad():\n",
    "                feats = prepare_sequence(embeddings).to(device)\n",
    "                _, pred_ids = model(feats)\n",
    "\n",
    "            ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "            pred_tags = [ix_to_tag[i.item()] for i in pred_ids]\n",
    "\n",
    "            raw_span = extract_span_from_tags(tokens, pred_tags)\n",
    "            if not raw_span:\n",
    "                continue\n",
    "\n",
    "            best_raw_span = raw_span\n",
    "\n",
    "            # extract all numbers from the raw span\n",
    "            nums = re.findall(r'\\d+(?:\\.\\d+)?', raw_span)\n",
    "            if len(nums) >= 2:\n",
    "                low, high = nums[0], nums[-1]\n",
    "            elif len(nums) == 1:\n",
    "                low = high = nums[0]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # normalize to integers for formatting\n",
    "            low_i = int(float(low))\n",
    "            high_i = int(float(high))\n",
    "            formatted_range = f\"{low_i}-{high_i}\"\n",
    "\n",
    "            best_prediction = f\"{formatted_range}-{currency.upper()}-{unit.upper()}\"\n",
    "            break\n",
    "\n",
    "        status = \"✅\" if (\n",
    "            best_prediction.replace(\" \", \"\").lower()\n",
    "            in y_true.replace(\" \", \"\").lower()\n",
    "        ) else \"❌\"\n",
    "\n",
    "        print(\n",
    "            f\"[{status}] Job ID {job_id}\\n\"\n",
    "            f\"    Raw span:    '{best_raw_span}'\\n\"\n",
    "            f\"    Formatted:   '{best_prediction}'\\n\"\n",
    "            f\"    Expected:    '{y_true}'\\n\"\n",
    "        )\n",
    "\n",
    "        total += 1\n",
    "        if status == \"✅\":\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    print(f\"\\nOverall Accuracy: {correct}/{total} = {accuracy:.2%}\\n\")\n",
    "\n",
    "# Run Evaluation\n",
    "evaluate_on_test_set(\"/Users/eddiezhang/Downloads/job_data_files/salary_labelled_test_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c85214",
   "metadata": {},
   "outputs": [],
   "source": [
    "How many are correct?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
