{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d14424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# === Device setup ===\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# === Load datasets ===\n",
    "dev_data = pd.read_csv('/Users/eddiezhang/Downloads/job_data_files/salary_labelled_development_set.csv')\n",
    "test_data = pd.read_csv('/Users/eddiezhang/Downloads/job_data_files/salary_labelled_test_set.csv')\n",
    "\n",
    "# === Map country to currency ===\n",
    "nation_currency = {\n",
    "    \"PH\": \"PHP\", \n",
    "    \"NZ\": \"NZD\", \n",
    "    \"AUS\": \"AUD\", \n",
    "    \"HK\": \"HKD\",\n",
    "    \"ID\": \"IDR\", \n",
    "    \"MY\": \"MYR\", \n",
    "    \"SG\": \"SGD\", \n",
    "    \"TH\": \"THB\"\n",
    "}\n",
    "dev_data['currency'] = dev_data.iloc[:, 3].map(nation_currency)\n",
    "test_data['currency'] = test_data.iloc[:, 3].map(nation_currency)\n",
    "\n",
    "# === Parse salary info ===\n",
    "def parse_actual_info(info_str):\n",
    "    try:\n",
    "        parts = info_str.split('-')\n",
    "        if len(parts) != 4 or parts == ['0', '0', 'None', 'None']:\n",
    "            return None\n",
    "        return (float(parts[0]), float(parts[1]), parts[2], parts[3].lower())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "dev_data['parsed'] = dev_data.iloc[:, 5].apply(parse_actual_info)\n",
    "test_data['parsed'] = test_data.iloc[:, 5].apply(parse_actual_info)\n",
    "dev_data = dev_data[dev_data['parsed'].notnull()]\n",
    "test_data = test_data[test_data['parsed'].notnull()]\n",
    "dev_data[['min_salary', 'max_salary', 'currency', 'unit']] = pd.DataFrame(dev_data['parsed'].tolist(), index=dev_data.index)\n",
    "test_data[['min_salary', 'max_salary', 'currency', 'unit']] = pd.DataFrame(test_data['parsed'].tolist(), index=test_data.index)\n",
    "\n",
    "# === Load BERT ===\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert.to(device)\n",
    "bert.eval()\n",
    "\n",
    "# === Helpers ===\n",
    "def label_tokens(text, salary_span):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    labels = ['O'] * len(tokens)\n",
    "    salary_tokens = tokenizer.tokenize(salary_span)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i:i+len(salary_tokens)] == salary_tokens:\n",
    "            labels[i] = 'B-SALARY'\n",
    "            for j in range(1, len(salary_tokens)):\n",
    "                labels[i + j] = 'I-SALARY'\n",
    "            break\n",
    "    return tokens, labels\n",
    "\n",
    "def get_token_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "def extract_span(tokens, labels):\n",
    "    span_tokens = []\n",
    "    inside = False\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label == \"B-SALARY\":\n",
    "            span_tokens = [token]\n",
    "            inside = True\n",
    "        elif label == \"I-SALARY\" and inside:\n",
    "            span_tokens.append(token)\n",
    "        elif inside:\n",
    "            break\n",
    "    return tokenizer.convert_tokens_to_string(span_tokens)\n",
    "\n",
    "def extract_numeric_range(span_str):\n",
    "    numbers = re.findall(r'\\d+(?:\\.\\d+)?', span_str)\n",
    "    if len(numbers) == 1:\n",
    "        val = float(numbers[0])\n",
    "        return val, val\n",
    "    elif len(numbers) >= 2:\n",
    "        return float(numbers[0]), float(numbers[1])\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def predict_currency(text):\n",
    "    for cur in [\"PHP\", \"NZD\", \"AUD\", \"HKD\", \"IDR\", \"MYR\", \"SGD\", \"THB\"]:\n",
    "        if cur.lower() in text.lower():\n",
    "            return cur\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "def predict_timeframe(text):\n",
    "    keywords = {\n",
    "        \"hourly\": [\"hour\", \"hr\", \"hourly\", \"ÊØèÂ∞èÊôÇ\", \"ÊôÇËñ™\"],\n",
    "        \"daily\": [\"day\", \"daily\", \"Êó•Ëñ™\", \"ÊØèÊó•\"],\n",
    "        \"weekly\": [\"week\", \"weekly\", \"Âë®Ëñ™\", \"ÊØèÈÄ±\"],\n",
    "        \"monthly\": [\"month\", \"monthly\", \"ÊúàËñ™\", \"ÊØèÊúà\"],\n",
    "        \"annual\": [\"year\", \"annual\", \"yearly\", \"annually\", \"Âπ¥Ëñ™\", \"ÊØèÂπ¥\"]\n",
    "    }\n",
    "    for unit, terms in keywords.items():\n",
    "        for t in terms:\n",
    "            if t in text.lower():\n",
    "                return unit\n",
    "    return \"unknown\"\n",
    "\n",
    "# === Training ===\n",
    "train_embeddings, train_labels = [], []\n",
    "\n",
    "for idx, row in dev_data.iterrows():\n",
    "    job_text = row.iloc[2]\n",
    "    salary_span = f\"{int(row['min_salary'])} to {int(row['max_salary'])}\"\n",
    "    tokens, labels = label_tokens(job_text, salary_span)\n",
    "    embeddings = get_token_embeddings(job_text)\n",
    "\n",
    "    if embeddings.shape[0] != len(tokens) or \"B-SALARY\" not in labels:\n",
    "        continue\n",
    "\n",
    "    train_embeddings.extend(embeddings.numpy())\n",
    "    train_labels.extend(labels)\n",
    "\n",
    "\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_train_labels = label_encoder.fit_transform(train_labels)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_embeddings, encoded_train_labels)\n",
    "\n",
    "\n",
    "# === Testing ===\n",
    "test_embeddings, test_labels = [], []\n",
    "test_tokens_list, test_true_labels_list = [], []\n",
    "skipped_test = 0\n",
    "\n",
    "for idx, row in dev_data.iterrows():\n",
    "    job_text = row.iloc[2]\n",
    "    salary_span = f\"{int(row['min_salary'])} to {int(row['max_salary'])}\"\n",
    "\n",
    "    if salary_span not in job_text:\n",
    "        continue\n",
    "\n",
    "    tokens, labels = label_tokens(job_text, salary_span)\n",
    "    embeddings = get_token_embeddings(job_text)\n",
    "\n",
    "    if embeddings.shape[0] != len(tokens):\n",
    "        continue\n",
    "\n",
    "    train_embeddings.extend(embeddings.numpy())\n",
    "    train_labels.extend(labels)\n",
    "\n",
    "test_preds = clf.predict(test_embeddings)\n",
    "id2label = {i: label for i, label in enumerate(label_encoder.classes_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation: Full prediction vs actual ===\n",
    "print(\"\\nüßæ Final Structured Predictions by Test Row\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "correct_full_match = 0\n",
    "total_rows = 0\n",
    "start_idx = 0\n",
    "\n",
    "for i, row in enumerate(test_data.itertuples()):\n",
    "    if i >= len(test_tokens_list):\n",
    "        break\n",
    "\n",
    "    job_text = row.job_ad_details\n",
    "    true_currency = getattr(row, \"currency\")\n",
    "    true_unit = getattr(row, \"unit\").lower()\n",
    "    true_min = int(getattr(row, \"min_salary\"))\n",
    "    true_max = int(getattr(row, \"max_salary\"))\n",
    "\n",
    "    tokens = test_tokens_list[i]\n",
    "    true_labels = test_true_labels_list[i]\n",
    "\n",
    "    \n",
    "    end_idx = start_idx + len(tokens)\n",
    "    pred_labels = [id2label[idx] for idx in test_preds[start_idx:end_idx]]\n",
    "    start_idx = end_idx\n",
    "\n",
    "    pred_span = extract_span(tokens, pred_labels)\n",
    "    pred_min, pred_max = extract_numeric_range(pred_span)\n",
    "    pred_currency = predict_currency(job_text)\n",
    "    pred_unit = predict_timeframe(job_text)\n",
    "\n",
    "    if pred_min is not None and pred_max is not None:\n",
    "        pred_string = f\"{int(pred_min)}-{int(pred_max)}-{pred_currency}-{pred_unit}\"\n",
    "    else:\n",
    "        pred_string = f\"0-0-NONE-NONE\"\n",
    "\n",
    "    true_string = f\"{true_min}-{true_max}-{true_currency}-{true_unit}\"\n",
    "    is_correct = pred_string.lower() == true_string.lower()\n",
    "\n",
    "    correct_full_match += int(is_correct)\n",
    "    total_rows += 1\n",
    "\n",
    "    print(f\"[Row {i}]\")\n",
    "    print(f\"Prediction: {pred_string}\")\n",
    "    print(f\"Actual:     {true_string}\")\n",
    "    print(\"‚úÖ CORRECT\" if is_correct else \"‚ùå INCORRECT\")\n",
    "    print()\n",
    "\n",
    "print(\"üîö Structured Prediction Summary\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"‚úîÔ∏è Total Test Rows Evaluated:   {total_rows}\")\n",
    "print(f\"üéØ Fully Correct Predictions:   {correct_full_match}\")\n",
    "print(f\"üéØ Final Match Accuracy:        {correct_full_match / total_rows * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
