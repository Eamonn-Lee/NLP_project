{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garry/vs_code/6713/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset:\n",
      "Precision: 0.7811\n",
      "Recall: 0.9370\n",
      "F1 Score: 0.8519\n",
      "Accuracy: 0.8489\n",
      "\n",
      "Test dataset:\n",
      "Precision: 0.7412\n",
      "Recall: 0.9206\n",
      "F1 Score: 0.8212\n",
      "Accuracy: 0.8219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append(\"../CODE-Baseline\")  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from salary_baseline import extract_salary_with_inference\n",
    "\n",
    "\n",
    "file_path = '../DATASETS/salary_labelled_development_set.csv'\n",
    "test_file_path = '../DATASETS/salary_labelled_test_set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "model_name = \"deepset/bert-base-cased-squad2\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html -> context \n",
    "def clean_html_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text(separator=\" \", strip=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_question = \"what is fixed salary or salary range?\"\n",
    "pay_freq_question = \"Is the salary paid monthly, hourly, yearly, weekly, or daily?\"\n",
    "\n",
    "def get_salary_using_nFT_Bert(text,nation_code):\n",
    "  context=clean_html_tags(text)\n",
    "  salary_result = qa_pipeline({\"context\": context, \"question\": salary_question})\n",
    "  t_result=extract_salary_with_inference(salary_result[\"answer\"],nation_code)\n",
    "  # print(t_result)\n",
    "  if t_result!='0-0-None-None':\n",
    "    pay_freq_result = qa_pipeline({\"context\": context, \"question\": pay_freq_question})\n",
    "    # print(pay_freq_result[\"answer\"])\n",
    "    \n",
    "  return t_result\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "df['predicted_salary'] = df.apply(\n",
    "    lambda row: get_salary_using_nFT_Bert(\n",
    "        f\"{row['job_title']} {row['job_ad_details']}\",\n",
    "        row['nation_short_desc']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP, FP, TN, FN\n",
    "TP = np.sum((df['predicted_salary'] == df['y_true']) & (df['y_true'] != \"0-0-None-None\"))\n",
    "FP = np.sum((df['predicted_salary'] != df['y_true']) & (df['predicted_salary'] != \"0-0-None-None\"))\n",
    "FN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] != \"0-0-None-None\"))\n",
    "TN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] == \"0-0-None-None\"))\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "accuracy = (TP + TN) / (FP + FN + TP + TN)\n",
    "\n",
    "# Print prediction vs ground truth\n",
    "# print(\"\\nüîç Prediction vs Ground Truth:\\n\")\n",
    "# for i, row in df.iterrows():\n",
    "#     predicted = row['predicted_salary']\n",
    "#     expected = row['y_true']\n",
    "#     if predicted != expected:\n",
    "#         print(f\"[{i}] ‚ùå Predicted: {predicted} | Expected: {expected}\")\n",
    "#         print(f\"{row['job_id']} {row['job_title']} {row['job_ad_details']}\")\n",
    "#         print()\n",
    "    # else:\n",
    "    #     print(f\"[{i}] ‚úÖ Matched:   {predicted}\")\n",
    "\n",
    "print(\"Development dataset:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "df = pd.read_csv(test_file_path)\n",
    "df['predicted_salary'] = df.apply(\n",
    "    lambda row: get_salary_using_nFT_Bert(\n",
    "        f\"{row['job_title']} {row['job_ad_details']}\",\n",
    "        row['nation_short_desc']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "TP = np.sum((df['predicted_salary'] == df['y_true']) & (df['y_true'] != \"0-0-None-None\"))\n",
    "FP = np.sum((df['predicted_salary'] != df['y_true']) & (df['predicted_salary'] != \"0-0-None-None\"))\n",
    "FN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] != \"0-0-None-None\"))\n",
    "TN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] == \"0-0-None-None\"))\n",
    "\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "accuracy = (TP + TN) / (FP + FN + TP + TN)\n",
    "\n",
    "print(\"Test dataset:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
