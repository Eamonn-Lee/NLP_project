{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset:\n",
      "Precision: 0.7811\n",
      "Recall: 0.9370\n",
      "F1 Score: 0.8519\n",
      "Accuracy: 0.8489\n",
      "\n",
      "Test dataset:\n",
      "Precision: 0.7412\n",
      "Recall: 0.9206\n",
      "F1 Score: 0.8212\n",
      "Accuracy: 0.8219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bae5f44e20471db6004bc93e33beaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cb2e787575430e8234bda0f1cc5074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00574654bd5f49e0815c500d8b356d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73784b7516e49e4ad79bdd063e32741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5e6f2a8bae4b93afd5f88980c4e5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe0d86c5f674cb4a0e9626fb6923a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append(\"../CODE-Baseline\")  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from salary_baseline import extract_salary_with_inference\n",
    "\n",
    "file_path = '../DATASETS/salary_labelled_development_set.csv'\n",
    "test_file_path = '../DATASETS/salary_labelled_test_set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html -> context \n",
    "def clean_html_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text(separator=\" \", strip=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'question: What is the salary? context: ‡πÄ‡∏£‡∏≤‡∏£'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ËæìÂÖ•ÈóÆÈ¢òÂíå‰∏ä‰∏ãÊñá\n",
    "question = \"What is the salary?\"\n",
    "context = '''\n",
    "Protege - Quantity Surveyor (KL) Description Quantity surveyors have under their helm complete management of the cost involved in building and construction projects from the inception of the project until the delivery. They strive for an efficient use of the resources whilst keeping an eye on quality, quality standards, and client's requirements. Contract Basic : 12 months Monthly Salary : RM2000.00 Annual Leave & Medical Leave Provided SOCSO & EIS Contribution *Candidate must be a Bachelor Degree holder* Company PANCARAN DINAR SDN BHD telah ditubuhkan pada tahun 1982. PANCARAN DINAR SDN BHD adalah sebuah Syarikat Bumiputera yang bergiat aktif dalam industry pembinaan di Pantai Timur Semenanjung. Sehingga kini projek-projek yang dikendalikan oleh PANCARAN DINAR SDN BHD merupakan kontrak daripada pihak kerajaan, badan berkanun dan pihak swasta. Jumlah kerja terkumpul yang telah dikendalikan oleh PANCARAN DINAR SDN BHD adalah melebihi RM400 juta merangkumi projek-projek pembinaan bangunan dan infrastruktur. PANCARAN DINAR SDN BHD merupakan sebuah syarikat yang berdaftar dengan Lembaga Pembangunan Industri Pembinaan Malaysia (CIDB) ‚Äì Kelas G7 dan berdaftar dengan Bahagian Pembangunan Kontraktor Dan Usahawan (BPKU) ‚Äì Taraf Bumiputera PANCARAN DINAR SDN BHD juga mendapat pengiktirafan ISO 9001:2015 oleh SIRIM QAS International Sdn. Bhd. bagi aktiviti penyediaan perkhidmatan pembinaan untuk bangunan, sivil dan kerja-kerja infrastruktur.\n",
    "\n",
    "'''\n",
    "input_text = f\"question: {question} context: {context}\"\n",
    "\n",
    "# ÁîüÊàêÁ≠îÊ°à\n",
    "output = qa_pipeline(input_text)\n",
    "\n",
    "# ÊâìÂç∞ÁîüÊàêÁöÑÁ≠îÊ°à\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salary_question = \"what is fixed salary or salary range?\"\n",
    "# pay_freq_question = \"Is the salary paid monthly, hourly, yearly, weekly, or daily?\"\n",
    "\n",
    "# def get_salary_using_nFT_Bert(text,nation_code):\n",
    "#   context=clean_html_tags(text)\n",
    "#   salary_result = qa_pipeline({\"context\": context, \"question\": salary_question})\n",
    "#   t_result=extract_salary_with_inference(salary_result[\"answer\"],nation_code)\n",
    "#   # print(t_result)\n",
    "#   if t_result!='0-0-None-None':\n",
    "#     pay_freq_result = qa_pipeline({\"context\": context, \"question\": pay_freq_question})\n",
    "#     # print(pay_freq_result[\"answer\"])\n",
    "    \n",
    "#   return t_result\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# df['predicted_salary'] = df.apply(\n",
    "#     lambda row: get_salary_using_nFT_Bert(\n",
    "#         f\"{row['job_title']} {row['job_ad_details']}\",\n",
    "#         row['nation_short_desc']\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TP, FP, TN, FN\n",
    "# TP = np.sum((df['predicted_salary'] == df['y_true']) & (df['y_true'] != \"0-0-None-None\"))\n",
    "# FP = np.sum((df['predicted_salary'] != df['y_true']) & (df['predicted_salary'] != \"0-0-None-None\"))\n",
    "# FN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] != \"0-0-None-None\"))\n",
    "# TN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] == \"0-0-None-None\"))\n",
    "\n",
    "# precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "# recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "# f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "# accuracy = (TP + TN) / (FP + FN + TP + TN)\n",
    "\n",
    "# # Print prediction vs ground truth\n",
    "# # print(\"\\nüîç Prediction vs Ground Truth:\\n\")\n",
    "# # for i, row in df.iterrows():\n",
    "# #     predicted = row['predicted_salary']\n",
    "# #     expected = row['y_true']\n",
    "# #     if predicted != expected:\n",
    "# #         print(f\"[{i}] ‚ùå Predicted: {predicted} | Expected: {expected}\")\n",
    "# #         print(f\"{row['job_id']} {row['job_title']} {row['job_ad_details']}\")\n",
    "# #         print()\n",
    "#     # else:\n",
    "#     #     print(f\"[{i}] ‚úÖ Matched:   {predicted}\")\n",
    "\n",
    "# print(\"Development dataset:\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test set\n",
    "# df = pd.read_csv(test_file_path)\n",
    "# df['predicted_salary'] = df.apply(\n",
    "#     lambda row: get_salary_using_nFT_Bert(\n",
    "#         f\"{row['job_title']} {row['job_ad_details']}\",\n",
    "#         row['nation_short_desc']\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# TP = np.sum((df['predicted_salary'] == df['y_true']) & (df['y_true'] != \"0-0-None-None\"))\n",
    "# FP = np.sum((df['predicted_salary'] != df['y_true']) & (df['predicted_salary'] != \"0-0-None-None\"))\n",
    "# FN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] != \"0-0-None-None\"))\n",
    "# TN = np.sum((df['predicted_salary'] == \"0-0-None-None\") & (df['y_true'] == \"0-0-None-None\"))\n",
    "\n",
    "\n",
    "# precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "# recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "# f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "# accuracy = (TP + TN) / (FP + FN + TP + TN)\n",
    "\n",
    "# print(\"Test dataset:\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
